{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "72c72a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio  # Import imageio\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os  # Import the os module\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization, RandomFlip\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt  # You mentioned importing matplotlib, so including it here\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "\n",
    "root_dir = os.path.abspath('D:/computer-science/03x01/02-24-03302-Deep-Learning/Sessions/02')\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "sub_dir = os.path.join(root_dir, 'sub')\n",
    "\n",
    "## reading train file only\n",
    "train = pd.read_csv(os.path.join(root_dir, 'Train', 'train.csv'))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b898b44c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAHfElEQVR4nO3coWvVbQPH4d950fHIFByIURBxLhlEFi0iBoPgEGa1CHaDf4M2YVWzYLRaTAoaDCbFJIKg4DCMoZynfcpbdu999jh9ryufL+dm4Xy4w+7ZfD6fTwAwTdN/fvUBANg/RAGAiAIAEQUAIgoARBQAiCgAEFEAIAd2+sHZbLaX5wBgj+3kf5XdFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgA58KsPALDXlpaWhjc/f/4c3mxubg5v9hs3BQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEA/iwf/g6NGjw5utra1dfdfhw4eHN7t51O3q1avDm1OnTg1vFhcXhzfTtLu/+fr6+vDm7du3w5vz588Pb/YbNwUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABAP4rHvXbhwYXizsrIyvLlx48bw5uzZs8ObpaWl4c1uff/+fXhz8ODB4c23b9+GN8ePHx/e/Jt28yDen8BNAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiFdSmQ4dOjS8uXv37vDm4sWLw5tpmqbV1dXhzcuXL4c3169fH97cunVreHPs2LHhzTRN04sXL4Y379+/H968e/duePP169fhzZkzZ4Y30zRNJ0+eHN5sbW0Nb549eza8+RO4KQAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgMzm8/l8Rx+czfb6LPwDFhYWhjdPnjwZ3ly5cmV48+XLl+HNNE3To0ePhjf37t0b3nz+/Hl4A7+TnfzcuykAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYAc+NUH4J+1vb09vHn69Onw5vTp08Ob5eXl4c00TdObN2+GNx63g91xUwAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAJnN5/P5jj44m+31WfiN/PXXX8Ob9fX1XX3X/fv3hzePHz8e3ty+fXt4A7+TnfzcuykAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYB4EI99b2NjY3hz8+bN4c3x48eHN5ubm8Mb+FU8iAfAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgA58KsP8Lu5dOnS8ObOnTvDmx0+XvtfLl++vKvdv2FxcXFXu0+fPg1vFhYWhjdra2vDm4cPHw5vYD9zUwAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCAPEg3qAHDx4Mb5aXl4c329vbw5tpmqbnz58Pb3bz4NzHjx+HN9euXRveTNM0nThxYnjz48eP4c3nz5+HN/CncVMAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgCZzefz+Y4+OJvt9Vl+CysrK8ObtbW14c3q6urwZpqm6dy5c8ObI0eO7Oq7Rn348GFXu9evXw9vNjY2hjevXr0a3sDvZCc/924KAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgHsQD+D/hQTwAhogCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYAc2OkH5/P5Xp4DgH3ATQGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgPwNDV60KZD9GEwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random  # Import the random module\n",
    "import imageio.v2 as imageio\n",
    "# ... (previous code) ...\n",
    "\n",
    "# Replace rng.choice with random.choice\n",
    "img_name = random.choice(train.filename)\n",
    "\n",
    "filepath = os.path.join(root_dir, 'Train', 'Images', 'train', img_name)\n",
    "\n",
    "img =imageio.imread(filepath)\n",
    "\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3d9e7316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]\n",
      "\n",
      "  [[0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   ...\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]\n",
      "   [0. 0. 0. 1.]]]]\n",
      "(49000, 28, 28, 4)\n"
     ]
    }
   ],
   "source": [
    "#storing images in numpy arrays\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    " image_path = os.path.join(root_dir, 'Train', 'Images', 'train', img_name)\n",
    " img = imageio.imread(image_path)\n",
    " img = img.astype('float32')\n",
    " temp.append(img)\n",
    " \n",
    "x_train = np.stack(temp)\n",
    "\n",
    "x_train /= 255.0\n",
    "\n",
    "print(x_train)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(train.label.values)\n",
    "# Split the data into training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "11e5db0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34300, 28, 28, 4)\n",
      "(34300, 10)\n",
      "(14700, 28, 28, 4)\n",
      "(14700, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "x_train_gen = x_train\n",
    "x_test_gen = x_test\n",
    "y_train_gen = y_train\n",
    "y_test_gen = y_test\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b918862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], -1).astype('float32')\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], -1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a7e6dcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34300, 3136)\n",
      "(34300, 10)\n",
      "(14700, 3136)\n",
      "(14700, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "000ec07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# define vars\n",
    "input_num_units = 3136\n",
    "hidden1_num_units = 500\n",
    "hidden2_num_units = 500\n",
    "hidden3_num_units = 500\n",
    "hidden4_num_units = 500\n",
    "hidden5_num_units = 500\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential([\n",
    "\n",
    " Dense(units=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dense(units=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dense(units=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dense(units=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dense(units=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    "\n",
    "Dense(units=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6a01e288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 0.4251 - accuracy: 0.8607 - val_loss: 0.2259 - val_accuracy: 0.9289\n",
      "Epoch 2/5\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 0.1859 - accuracy: 0.9421 - val_loss: 0.1695 - val_accuracy: 0.9485\n",
      "Epoch 3/5\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 0.1520 - accuracy: 0.9537 - val_loss: 0.2596 - val_accuracy: 0.9199\n",
      "Epoch 4/5\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 0.1289 - accuracy: 0.9594 - val_loss: 0.1561 - val_accuracy: 0.9541\n",
      "Epoch 5/5\n",
      "268/268 [==============================] - 2s 8ms/step - loss: 0.1094 - accuracy: 0.9652 - val_loss: 0.1546 - val_accuracy: 0.9569\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_5d = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2139715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "model2 = Sequential([\n",
    " Dense(units=hidden1_num_units, input_dim=input_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.000001)),\n",
    " Dense(units=hidden2_num_units, input_dim=hidden1_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.000001)),\n",
    " Dense(units=hidden3_num_units, input_dim=hidden2_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.000001)),\n",
    " Dense(units=hidden4_num_units, input_dim=hidden3_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.000001)),\n",
    " Dense(units=hidden5_num_units, input_dim=hidden4_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.000001)),\n",
    "\n",
    "Dense(units=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b8dacc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 0.4264 - accuracy: 0.8621 - val_loss: 0.2353 - val_accuracy: 0.9298\n",
      "Epoch 2/5\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 0.1974 - accuracy: 0.9385 - val_loss: 0.1745 - val_accuracy: 0.9499\n",
      "Epoch 3/5\n",
      "268/268 [==============================] - 2s 9ms/step - loss: 0.1567 - accuracy: 0.9513 - val_loss: 0.1353 - val_accuracy: 0.9606\n",
      "Epoch 4/5\n",
      "268/268 [==============================] - 3s 9ms/step - loss: 0.1215 - accuracy: 0.9632 - val_loss: 0.1599 - val_accuracy: 0.9528\n",
      "Epoch 5/5\n",
      "268/268 [==============================] - 3s 9ms/step - loss: 0.1154 - accuracy: 0.9641 - val_loss: 0.1252 - val_accuracy: 0.9654\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_5d = model2.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "78bbb2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## l1\n",
    "\n",
    "model3 = Sequential([\n",
    " Dense(units=hidden1_num_units, input_dim=input_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(units=hidden2_num_units, input_dim=hidden1_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(units=hidden3_num_units, input_dim=hidden2_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(units=hidden4_num_units, input_dim=hidden3_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(units=hidden5_num_units, input_dim=hidden4_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    "\n",
    "Dense(units=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aef3e19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 2.9510 - accuracy: 0.8452 - val_loss: 1.7421 - val_accuracy: 0.9280\n",
      "Epoch 2/5\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 1.5063 - accuracy: 0.9186 - val_loss: 1.2628 - val_accuracy: 0.9294\n",
      "Epoch 3/5\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 1.0720 - accuracy: 0.9349 - val_loss: 0.9378 - val_accuracy: 0.9394\n",
      "Epoch 4/5\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 0.8138 - accuracy: 0.9436 - val_loss: 0.7720 - val_accuracy: 0.9328\n",
      "Epoch 5/5\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 0.6585 - accuracy: 0.9489 - val_loss: 0.6321 - val_accuracy: 0.9393\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model3.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e60024bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropout\n",
    "\n",
    "from keras.layers.core import Dropout\n",
    "model4 = Sequential([\n",
    " Dense(units=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(units=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(units=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(units=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(units=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    "\n",
    "Dense(units=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "00cae07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "268/268 [==============================] - 3s 11ms/step - loss: 0.6846 - accuracy: 0.7725 - val_loss: 0.2838 - val_accuracy: 0.9169\n",
      "Epoch 2/5\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 0.3440 - accuracy: 0.8973 - val_loss: 0.2212 - val_accuracy: 0.9380\n",
      "Epoch 3/5\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 0.2899 - accuracy: 0.9163 - val_loss: 0.1858 - val_accuracy: 0.9465\n",
      "Epoch 4/5\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 0.2507 - accuracy: 0.9273 - val_loss: 0.1846 - val_accuracy: 0.9489\n",
      "Epoch 5/5\n",
      "268/268 [==============================] - 3s 10ms/step - loss: 0.2335 - accuracy: 0.9320 - val_loss: 0.1877 - val_accuracy: 0.9468\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model4.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa6518",
   "metadata": {},
   "source": [
    "## Let's Try Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5fe9c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGenerator = ImageDataGenerator(\n",
    "        # rescale=1/255,          # Normalization (between 0 , 1)\n",
    "        validation_split=0.1,   # Validation Split (10%)\n",
    "        rotation_range=20,      # randomly rotating the image by 30 degrees (agumentation)\n",
    "        width_shift_range=0.2,  # shift the width of the image by 20% (agumentation)\n",
    "        height_shift_range=0.2, # shift the height of the image by 20%  (agumentation)\n",
    "        horizontal_flip=True    # randomly flip the image horizontally  (agumentation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bd676f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = trainGenerator.flow(x_train_gen, y_train_gen, batch_size=128)\n",
    "test_batches = trainGenerator.flow(x_test_gen, y_test_gen, batch_size=128)\n",
    "# batches = trainGenerator.flow(x_train, y_train, batch_size=64)\n",
    "# val_batches=trainGenerator.flow(x_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9eb67d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(units=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    "    Dense(units=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    "    Dense(units=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    "    Dense(units=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    "    Dense(units=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    "    Dense(units=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "03abd844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "268/268 [==============================] - 18s 65ms/step - loss: 0.5694 - accuracy: 0.8066 - val_loss: 0.5347 - val_accuracy: 0.8228\n",
      "Epoch 2/25\n",
      "268/268 [==============================] - 17s 63ms/step - loss: 0.5276 - accuracy: 0.8212 - val_loss: 0.5239 - val_accuracy: 0.8245\n",
      "Epoch 3/25\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.4953 - accuracy: 0.8326 - val_loss: 0.5265 - val_accuracy: 0.8246\n",
      "Epoch 4/25\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.4800 - accuracy: 0.8386 - val_loss: 0.4799 - val_accuracy: 0.8439\n",
      "Epoch 5/25\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.4664 - accuracy: 0.8439 - val_loss: 0.4325 - val_accuracy: 0.8551\n",
      "Epoch 6/25\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.4468 - accuracy: 0.8510 - val_loss: 0.4186 - val_accuracy: 0.8624\n",
      "Epoch 7/25\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.4252 - accuracy: 0.8573 - val_loss: 0.4096 - val_accuracy: 0.8628\n",
      "Epoch 8/25\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 0.4225 - accuracy: 0.8592 - val_loss: 0.4038 - val_accuracy: 0.8641\n",
      "Epoch 9/25\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.4036 - accuracy: 0.8635 - val_loss: 0.4182 - val_accuracy: 0.8601\n",
      "Epoch 10/25\n",
      "268/268 [==============================] - 18s 65ms/step - loss: 0.3985 - accuracy: 0.8662 - val_loss: 0.3912 - val_accuracy: 0.8702\n",
      "Epoch 11/25\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.3970 - accuracy: 0.8669 - val_loss: 0.3954 - val_accuracy: 0.8697\n",
      "Epoch 12/25\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3815 - accuracy: 0.8724 - val_loss: 0.4045 - val_accuracy: 0.8675\n",
      "Epoch 13/25\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3740 - accuracy: 0.8754 - val_loss: 0.3905 - val_accuracy: 0.8727\n",
      "Epoch 14/25\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3811 - accuracy: 0.8731 - val_loss: 0.3599 - val_accuracy: 0.8839\n",
      "Epoch 15/25\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3618 - accuracy: 0.8800 - val_loss: 0.3629 - val_accuracy: 0.8827\n",
      "Epoch 16/25\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.3508 - accuracy: 0.8832 - val_loss: 0.3348 - val_accuracy: 0.8912\n",
      "Epoch 17/25\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3516 - accuracy: 0.8837 - val_loss: 0.3400 - val_accuracy: 0.8877\n",
      "Epoch 18/25\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.3444 - accuracy: 0.8829 - val_loss: 0.3658 - val_accuracy: 0.8802\n",
      "Epoch 19/25\n",
      "268/268 [==============================] - 18s 66ms/step - loss: 0.3425 - accuracy: 0.8873 - val_loss: 0.3772 - val_accuracy: 0.8794\n",
      "Epoch 20/25\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.3410 - accuracy: 0.8892 - val_loss: 0.3449 - val_accuracy: 0.8867\n",
      "Epoch 21/25\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3299 - accuracy: 0.8909 - val_loss: 0.3508 - val_accuracy: 0.8871\n",
      "Epoch 22/25\n",
      "268/268 [==============================] - 18s 67ms/step - loss: 0.3254 - accuracy: 0.8934 - val_loss: 0.3327 - val_accuracy: 0.8901\n",
      "Epoch 23/25\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.3346 - accuracy: 0.8903 - val_loss: 0.3475 - val_accuracy: 0.8866\n",
      "Epoch 24/25\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3166 - accuracy: 0.8946 - val_loss: 0.3310 - val_accuracy: 0.8918\n",
      "Epoch 25/25\n",
      "268/268 [==============================] - 17s 65ms/step - loss: 0.3111 - accuracy: 0.8965 - val_loss: 0.3278 - val_accuracy: 0.8939\n"
     ]
    }
   ],
   "source": [
    "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history5 = model5.fit(batches,epochs=25,validation_data=test_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206529b6",
   "metadata": {},
   "source": [
    "# Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eec59f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = EarlyStopping(\n",
    "    patience=5,\n",
    "    monitor='val_accuracy',\n",
    "    restore_best_weights=True, # restore the model back to the best state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "56508d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3109 - accuracy: 0.8964 - val_loss: 0.3194 - val_accuracy: 0.8969\n",
      "Epoch 2/5\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3092 - accuracy: 0.8977 - val_loss: 0.3122 - val_accuracy: 0.8998\n",
      "Epoch 3/5\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3120 - accuracy: 0.8960 - val_loss: 0.3081 - val_accuracy: 0.9001\n",
      "Epoch 4/5\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3062 - accuracy: 0.9002 - val_loss: 0.3046 - val_accuracy: 0.8969\n",
      "Epoch 5/5\n",
      "268/268 [==============================] - 17s 64ms/step - loss: 0.3019 - accuracy: 0.9003 - val_loss: 0.3012 - val_accuracy: 0.9032\n"
     ]
    }
   ],
   "source": [
    "history5 = model5.fit(\n",
    "    batches,\n",
    "    epochs=5,\n",
    "    validation_data=test_batches,\n",
    "    callbacks=[stop_early])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
